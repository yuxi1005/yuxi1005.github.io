<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <!--Description-->

    

    
        <meta name="description" content="我的小窝"/>
    

    <!--Author-->
    
        <meta name="author" content="Yuxi"/>
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="关于Transformer"/>
    

    <!--Open Graph Description-->
    
        <meta property="og:description" content="我的小窝"/>
    

    <!--Open Graph Site Name-->
        <meta property="og:site_name" content="yuxi"/>

    <!--Type page-->
    
        <meta property="og:type" content="article"/>
    

    <!--Page Cover-->
    
    
        <meta property="og:image" content="https://yuxi1005.github.ioimg/ocean.jpg"/>
    

        <meta name="twitter:card" content="summary_large_image"/>

    

    
        <meta name="twitter:image" content="https://yuxi1005.github.ioimg/ocean.jpg"/>
    

    <!-- Title -->
    
    <title>关于Transformer - yuxi</title>

    <!-- Bootstrap Core CSS -->
    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"/>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css"/>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet"/>

    <!-- Google Analytics -->
    


    <!-- favicon -->
    

<meta name="generator" content="Hexo 7.3.0"></head>


<body>

    <!-- Menu -->
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Configurable Title</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <a href="/">
                            
                                Home
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/archives">
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags">
                            
                                Tags
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/categories">
                            
                                Categories
                            
                        </a>
                    </li>
                
                    <li>
                        <a target="_blank" rel="noopener" href="https://github.com/klugjo/hexo-theme-clean-blog">
                            
                                <i class="fa fa-github fa-stack-2x"></i>
                            
                        </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Main Content -->
    <!-- Page Header -->
<!-- Set your background image for this header in your post front-matter: cover -->

<header class="intro-header" style="background-image: url('/img/ocean.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>关于Transformer</h1>
                    
                    <span class="meta">
                        <!-- Date and Author -->
                        
                        
                            2025-02-24
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Tags and categories -->
           
                <div class="col-lg-4 col-lg-offset-2 col-md-5 col-md-offset-1 post-tags">
                    
                        


<a href="/tags/读论文/">#读论文</a> <a href="/tags/transformer/">#transformer</a>


                    
                </div>
                <div class="col-lg-4 col-md-5 post-categories">
                    
                        

<a href="/categories/笔/">笔</a>

                    
                </div>
            

            <!-- Gallery -->
            

            <!-- Post Main Content -->
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <h2 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h2><h3 id="Transformer-全面介绍"><a href="#Transformer-全面介绍" class="headerlink" title="Transformer 全面介绍"></a>Transformer 全面介绍</h3><hr>
<h4 id="一、背景与意义"><a href="#一、背景与意义" class="headerlink" title="一、背景与意义"></a>一、背景与意义</h4><p>一个文本变换模型：序列到序列</p>
<p><strong>Transformer</strong> 是谷歌于2017年在论文《Attention Is All You Need》中提出的深度学习模型架构。它通过<strong>自注意力机制（Self-Attention）</strong>完全替代了传统的循环神经网络（RNN）和卷积神经网络（CNN），解决了以下核心问题：  </p>
<ol>
<li><strong>长距离依赖</strong>：RNN难以捕捉长序列中的远距离关联。  </li>
<li><strong>并行计算</strong>：Transformer无需按序列顺序处理数据，可并行计算，大幅提升训练效率。  </li>
<li><strong>模型泛化</strong>：通过注意力机制动态学习不同位置的权重，适应多样化的上下文关系。</li>
</ol>
<span id="more"></span>

<hr>
<h4 id="二、核心架构"><a href="#二、核心架构" class="headerlink" title="二、核心架构"></a>二、核心架构</h4><p><img src="https://raw.githubusercontent.com/yuxi1005/yuxi1005.github.io/master/pictures/image-20250303171124090.png" alt="image-20250303171124090"></p>
<p>Transformer由<strong>编码器（Encoder）</strong>和<strong>解码器（Decoder）</strong>堆叠而成，每层结构独立且参数不共享。以下为关键组件：  </p>
<h5 id="1-编码器（Encoder）"><a href="#1-编码器（Encoder）" class="headerlink" title="1. 编码器（Encoder）"></a>1. <strong>编码器（Encoder）</strong></h5><ul>
<li><strong>输入嵌入（Input Embedding）</strong>：将输入词转换为高维向量。  </li>
<li><strong>位置编码（Positional Encoding）</strong>：为词向量注入位置信息（因Transformer无时序处理能力）。  </li>
<li><strong>多头自注意力（Multi-Head Self-Attention）</strong>：捕捉词与词之间的全局依赖关系。  </li>
<li><strong>前馈网络（Feed-Forward Network）</strong>：通过全连接层进行非线性变换。  </li>
<li><strong>残差连接（Residual Connection）</strong>与<strong>层归一化（Layer Normalization）</strong>：缓解梯度消失，加速收敛。</li>
</ul>
<h5 id="2-解码器（Decoder）"><a href="#2-解码器（Decoder）" class="headerlink" title="2. 解码器（Decoder）"></a>2. <strong>解码器（Decoder）</strong></h5><ul>
<li><strong>掩码多头注意力（Masked Multi-Head Attention）</strong>：防止未来信息泄露（训练时仅关注当前位置之前的词）。  </li>
<li><strong>编码器-解码器注意力（Encoder-Decoder Attention）</strong>：将编码器的输出作为Key和Value，解码器输入作为Query，实现跨序列对齐。  </li>
<li>其余结构与编码器类似（前馈网络、残差连接等）。</li>
</ul>
<hr>
<h4 id="三、自注意力机制（Self-Attention）"><a href="#三、自注意力机制（Self-Attention）" class="headerlink" title="三、自注意力机制（Self-Attention）"></a>三、自注意力机制（Self-Attention）</h4><p><strong>自注意力是Transformer的核心</strong>，通过计算词与词之间的关联权重，动态聚合上下文信息。其计算过程如下：  </p>
<ol>
<li><p><strong>生成Q、K、V矩阵</strong>：  </p>
<p>输入向量通过线性变换生成<strong>查询（Query）、键（Key）、值（Value）</strong>矩阵。  </p>
</li>
<li><p><strong>计算注意力分数</strong>：  </p>
<p>通过点积计算词与词之间的相似度，再缩放（防止梯度爆炸）并归一化：<br>$$<br>\text{Attention}(Q, K, V) &#x3D; \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V\<br>{d_k}为Key的维度<br>$$</p>
</li>
<li><p><strong>多头注意力（Multi-Head）</strong>：  </p>
<ul>
<li>将Q、K、V拆分为多个子空间（如8个“头”），分别计算注意力后拼接结果，增强模型捕捉不同层面信息的能力。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="四、位置编码（Positional-Encoding）"><a href="#四、位置编码（Positional-Encoding）" class="headerlink" title="四、位置编码（Positional Encoding）"></a>四、位置编码（Positional Encoding）</h4><p>因为transformer是并行计算每个词语的Attention的，所以没法考虑到语序问题。因此引入了位置编码。通过位置编码为输入序列注入位置信息。</p>
<ul>
<li><p><strong>正弦与余弦函数</strong>：<br>$$<br>PE_{(pos, 2i)} &#x3D; \sin\left(\frac{pos}{10000^{2i&#x2F;d_{\text{model}}}}\right), \quad<br>PE_{(pos, 2i+1)} &#x3D; \cos\left(\frac{pos}{10000^{2i&#x2F;d_{\text{model}}}}\right)<br>$$<br>(pos)：词的位置，(i)：维度索引。  </p>
<p>可泛化到任意长度的序列，且能通过线性变换捕捉相对位置关系。</p>
</li>
</ul>
<hr>
<h4 id="五、前馈网络（Feed-Forward-Network）"><a href="#五、前馈网络（Feed-Forward-Network）" class="headerlink" title="五、前馈网络（Feed-Forward Network）"></a>五、前馈网络（Feed-Forward Network）</h4><p>每个注意力层后接一个全连接前馈网络，包含两次线性变换和ReLU激活函数：<br>$$<br>\text{FFN}(x) &#x3D; \max(0, xW_1 + b_1)W_2 + b_2<br>$$</p>
<ul>
<li>作用：增强模型的非线性表达能力。</li>
</ul>
<hr>
<h4 id="六、训练与优化"><a href="#六、训练与优化" class="headerlink" title="六、训练与优化"></a>六、训练与优化</h4><ol>
<li><strong>损失函数</strong>：交叉熵损失（如机器翻译任务）。  </li>
<li><strong>优化器</strong>：Adam优化器，结合学习率预热（Warmup）和衰减策略。  </li>
<li><strong>正则化</strong>：  <ul>
<li>Dropout：应用于注意力权重和全连接层。  </li>
<li>标签平滑（Label Smoothing）：缓解过拟合。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="七、优势与局限性"><a href="#七、优势与局限性" class="headerlink" title="七、优势与局限性"></a>七、优势与局限性</h4><h5 id="优势："><a href="#优势：" class="headerlink" title="优势："></a>优势：</h5><ul>
<li><strong>并行计算</strong>：显著提升训练速度。  </li>
<li><strong>全局上下文建模</strong>：自注意力机制可捕捉任意距离的依赖关系。  </li>
<li><strong>可扩展性</strong>：模型深度和宽度灵活调整（如BERT、GPT等变体）。</li>
</ul>
<h5 id="局限性："><a href="#局限性：" class="headerlink" title="局限性："></a>局限性：</h5><ul>
<li><strong>计算复杂度</strong>：序列长度(n)的平方级复杂度（(O(n^2))），难以处理超长序列。  </li>
<li><strong>位置编码瓶颈</strong>：预设的位置编码可能无法完美适应所有任务。  </li>
<li><strong>显存消耗</strong>：多头注意力导致参数量较大。</li>
</ul>
<hr>
<h4 id="八、重要变体与改进"><a href="#八、重要变体与改进" class="headerlink" title="八、重要变体与改进"></a>八、重要变体与改进</h4><ol>
<li><strong>BERT</strong>：仅用编码器，通过掩码语言模型预训练。  </li>
<li><strong>GPT系列</strong>：仅用解码器，自回归生成文本。  </li>
<li><strong>Efficient Transformers</strong>：  <ul>
<li><strong>Longformer</strong>：稀疏注意力机制处理长文本。  </li>
<li><strong>Linformer</strong>：低秩近似降低计算复杂度。</li>
</ul>
</li>
<li><strong>视觉Transformer（ViT）</strong>：将图像分块输入Transformer。</li>
</ol>
<hr>
<h4 id="九、总结"><a href="#九、总结" class="headerlink" title="九、总结"></a>九、总结</h4><p>Transformer凭借其<strong>自注意力机制</strong>和<strong>并行化设计</strong>，成为深度学习领域的基石模型。它不仅推动了NLP的快速发展，还跨界影响了计算机视觉、语音识别等领域。尽管存在计算复杂度高、长序列处理难等挑战，其灵活性和强大性能使其成为AI模型设计的核心范式。后续的改进模型（如稀疏注意力、模型压缩等）进一步扩展了其应用边界，奠定了其在现代AI中的核心地位。</p>
<h2 id="关于前馈网络层"><a href="#关于前馈网络层" class="headerlink" title="关于前馈网络层"></a>关于前馈网络层</h2><p>前馈网络层，特别是在前馈神经网络中，扮演着至关重要的角色。前馈神经网络是一种最简单的神经网络，各神经元分层排列，每个神经元只与前一层的神经元相连，接收前一层的输出，并输出给下一层，各层间没有反馈。前馈网络层的作用：</p>
<ol>
<li><p><strong>特征提取与转换</strong></p>
<p>隐藏层（即前馈网络中的中间层）的主要功能是提取输入数据的特征和抽象表示。通过具有多个隐藏层，神经网络可以学习输入数据中越来越复杂和抽象的特征。隐藏层中的每个神经元都接收来自前一层神经元的输入，对其进行处理（如加权、求和、激活等），并将其传递到下一层。这样，隐藏层可以转换输入数据并提取有用的特征，从而使网络能够学习输入和输出之间更复杂和抽象的关系。</p>
</li>
<li><p><strong>非线性映射</strong>：</p>
<p>激活函数（如ReLU、sigmoid、tanh等）在隐藏层中的应用引入了非线性，使得神经网络能够学习和建模输入和输出之间更复杂的非线性关系。</p>
</li>
<li><p><strong>信息传递与整合</strong>：</p>
<p>在前馈神经网络中，信息从输入层流向隐藏层，再流向输出层，而不会循环回馈。这种单向信息传递的方式使得网络结构清晰、易于理解和实现。同时，每一层都接收来自前一层的信息，并对其进行整合和处理，最终生成网络的输出。</p>
</li>
</ol>


                
            </div>

            <!-- Comments -->
            
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    


                </div>
            
        </div>
    </div>
</article>

    <!-- Footer -->
    <hr />

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    

                    

                    

                    

                    

                    
                </ul>
                <p class="copyright text-muted">&copy; 2025 Yuxi<br></p>
                <p class="copyright text-muted">Original Theme <a target="_blank" href="http://startbootstrap.com/template-overviews/clean-blog/">Clean Blog</a> from <a href="http://startbootstrap.com/" target="_blank">Start Bootstrap</a></p>
                <p class="copyright text-muted">Adapted for <a target="_blank" href="https://hexo.io/">Hexo</a> by <a href="http://www.codeblocq.com/" target="_blank">Jonathan Klughertz</a></p>
            </div>
        </div>
    </div>
</footer>


    <!-- After footer scripts -->
    
<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Bootstrap -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->



</body>

</html>